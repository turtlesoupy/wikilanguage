{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tempfile\n",
    "import pipelines\n",
    "from db import WikilanguageDB\n",
    "import time\n",
    "import os\n",
    "import graph_tool\n",
    "import graph_tool.search\n",
    "from collections import defaultdict\n",
    "from wikidata_parser import WikiDataParser, WikiData, WikiDataInheritanceGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inheritance_graph = WikiDataInheritanceGraph.load(\"data/wikidata_inheritance.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract object',\n",
       " 'artificial entity',\n",
       " 'artificial geographic entity',\n",
       " 'artificial physical object',\n",
       " 'city/town',\n",
       " 'community',\n",
       " 'concrete object',\n",
       " 'entity',\n",
       " 'geographic entity',\n",
       " 'geographic location',\n",
       " 'geographic region',\n",
       " 'geographical object',\n",
       " 'group',\n",
       " 'group of humans',\n",
       " 'group of living things',\n",
       " 'group of physical objects',\n",
       " 'human settlement',\n",
       " 'human-geographic territorial entity',\n",
       " 'locality',\n",
       " 'location',\n",
       " 'object',\n",
       " 'object of science',\n",
       " 'physical object',\n",
       " 'physical system',\n",
       " 'product',\n",
       " 'research object',\n",
       " 'social group',\n",
       " 'spacio-temporal entity',\n",
       " 'spatial entity',\n",
       " 'statistical territorial entity',\n",
       " 'structure',\n",
       " 'system',\n",
       " 'territorial entity',\n",
       " 'unit',\n",
       " 'unit of analysis',\n",
       " 'urban area',\n",
       " 'work'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(r_inheritance.label_for_id(e) for e in r_inheritance.descendent_ids(\"Q515\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city', 'community', 'structure', 'entity', 'system', 'social group']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inheritance_graph.label_for_id(p) for p in tb.parents(\"Q515\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-6312dca8a2c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#pipelines.write_articles_into_db(db, \"wikis/jawiki-20190920-pages-articles-multistream.xml.bz2\", \"jawiki\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mwrite_wikidata_into_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wikis/wikidata-latest-all.json.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minheritance_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-f0c46e13efea>\u001b[0m in \u001b[0;36mwrite_wikidata_into_db\u001b[0;34m(db, input_path, inheritance_graph, whitelisted_wikis, limit, db_batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_wikidata_into_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minheritance_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhitelisted_wikis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minheritance_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         for i, entries in enumerate(grouper(db_batch_size, WikiDataParser.parse_dump(\n",
      "\u001b[0;32m~/projects/wikipedia-language-rank/wikidata_parser.py\u001b[0m in \u001b[0;36mparent_finder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mParentFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ae5eba40d9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(iter({}.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(n, iterable):\n",
    "    args = [iter(iterable)] * n\n",
    "    return ([e for e in t if e != None] for t in itertools.zip_longest(*args))\n",
    "\n",
    "def write_wikidata_into_db(db, input_path, parent_finder, whitelisted_wikis=None, limit=None, db_batch_size=10000):\n",
    "    start = time.time()\n",
    "    with pipelines._buffered_stream(input_path) as f:\n",
    "        for i, entries in enumerate(grouper(db_batch_size, WikiDataParser.parse_dump(\n",
    "            f, whitelisted_wikis=whitelisted_wikis\n",
    "        ))):\n",
    "            page_num = i * db_batch_size\n",
    "            if limit and page_num > limit:\n",
    "                break\n",
    "                \n",
    "            with db.con as cur:\n",
    "                # Insert concept record\n",
    "                cur.executemany(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO concepts(\n",
    "                        concept_id, sample_title, coord_latitude, coord_longitude, coord_altitude, coord_precision\n",
    "                    ) \n",
    "                    VALUES(?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        (\n",
    "                            e.id,\n",
    "                            e.sample_title,\n",
    "                            e.sample_coord and e.sample_coord.latitude,\n",
    "                            e.sample_coord and e.sample_coord.longitude,\n",
    "                            e.sample_coord and e.sample_coord.altitude,\n",
    "                            e.sample_coord and e.sample_coord.precision,\n",
    "                        )\n",
    "                        for e in entries\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                print(\"Done concepts\")\n",
    "                \n",
    "                # Insert article records\n",
    "                cur.executemany(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO concept_articles(\n",
    "                        concept_id, wiki, article_title\n",
    "                    ) \n",
    "                    VALUES(?, ?, ?)\n",
    "                    \"\"\",\n",
    "                    itertools.chain.from_iterable(\n",
    "                        (\n",
    "                            (\n",
    "                                e.id,\n",
    "                                wiki,\n",
    "                                title,\n",
    "                            ) \n",
    "                            for wiki, title in e.titles_by_wiki.items()\n",
    "                        ) for e in entries\n",
    "                    ),\n",
    "                )\n",
    "                \n",
    "                print(\"Done records\")\n",
    "                \n",
    "                # Insert instance of records\n",
    "                instances = []\n",
    "                for e in entries:\n",
    "                    parent_concepts = set()\n",
    "                    for c in e.direct_instance_of:\n",
    "                        parent_finder.all_parents(c, parent_concepts)\n",
    "                            \n",
    "                    for parent_concept in parent_concepts:\n",
    "                        instances.append((e.id, parent_concept))\n",
    "                    \n",
    "                cur.executemany(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO concept_instance_of (\n",
    "                        concept_id,\n",
    "                        instance_of_concept_id\n",
    "                    )\n",
    "                    VALUES (?, ?)\n",
    "                    \"\"\", \n",
    "                    instances,\n",
    "                )\n",
    "                \n",
    "                print(\"Done instances\")\n",
    "\n",
    "                \n",
    "                \n",
    "                if page_num % 100000 == 0:\n",
    "                    delta = time.time() - start\n",
    "                    pps = page_num / delta\n",
    "                    print(f\"DB Write: made it to page {page_num} in {delta:.2f}s {pps:.2f}pps\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_finder = inheritance_graph.parent_finder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 10000 in 3.262936592102051s [58.71600149293995% in json](3064.7239741664102 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "DB Write: made it to page 0 in 5.71s 0.00pps\n",
      "Reached 20000 in 8.074604511260986s [40.69738738902068% in json](2476.901496798716 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 30000 in 13.432533025741577s [41.45871201177803% in json](2233.3836769661525 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 40000 in 18.49702548980713s [37.00012147124362% in json](2162.5098598713716 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 50000 in 22.80553698539734s [35.072333845477765% in json](2192.4500191341954 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 60000 in 27.362179040908813s [33.751848348373116% in json](2192.807813672107 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 70000 in 32.07599139213562s [32.33125453376174% in json](2182.31758277509 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 80000 in 36.48492169380188s [31.16377471639286% in json](2192.686630148107 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 90000 in 41.40075182914734s [30.019227072635992% in json](2173.8735656640265 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 100000 in 45.485676765441895s [29.007919960229113% in json](2198.4942758063085 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 110000 in 49.63923144340515s [28.439480082487382% in json](2215.9891843896407 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "DB Write: made it to page 100000 in 52.13s 1918.41pps\n",
      "Reached 120000 in 53.6230890750885s [27.863254964995416% in json](2237.841983179369 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 130000 in 57.93366861343384s [27.379851332856536% in json](2243.9455865885766 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 140000 in 61.87454795837402s [26.89184973725252% in json](2262.6427928683165 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 150000 in 66.01305937767029s [26.36431959323551% in json](2272.277658604311 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 160000 in 69.62838530540466s [26.11033016534248% in json](2297.9134055487075 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 170000 in 73.35071659088135s [25.81249105085835% in json](2317.632436342601 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 180000 in 76.93138098716736s [25.44162158119419% in json](2339.7474176373507 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 190000 in 80.45940232276917s [25.239947813856812% in json](2361.439365877964 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 200000 in 83.88889694213867s [25.10462987286919% in json](2384.105731393125 lines per second)\n",
      "Done concepts\n",
      "Done records\n",
      "Done instances\n",
      "Reached 210000 in 87.35848474502563s [24.921822540128638% in json](2403.8878491646205 lines per second)\n",
      "Done concepts\n",
      "Done records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove(\"test.db\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "with WikilanguageDB.con(\"test.db\") as db:\n",
    "    db.create_tables()\n",
    "    #pipelines.write_articles_into_db(db, \"wikis/jawiki-20190920-pages-articles-multistream.xml.bz2\", \"jawiki\")\n",
    "    write_wikidata_into_db(db, \"wikis/wikidata-latest-all.json.gz\", parent_finder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wikilanguage)",
   "language": "python",
   "name": "wikilanguage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
